{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "236c9001-3578-4512-b577-931f8de7534c",
   "metadata": {},
   "source": [
    "# 1. chatGPT API 사용법\n",
    "\n",
    "이번 챕터에서는 chatGPT API 사용법을 익혀봅니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925b5ffc-bcf1-4535-a63f-f9b42b6ea874",
   "metadata": {},
   "source": [
    "## openai client library\n",
    "\n",
    "python으로 chatGPT API를 사용하려면 openai에서 제공하는 client library를 사용하는 것이 편합니다.  \n",
    "설치한 다음, import 해주고 앞서 발급받은 API key를 지정해주겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05d06abe-536b-4b85-b4f5-8321f251d0d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /Users/user/miniconda3/lib/python3.10/site-packages (1.2.3)\n",
      "Requirement already satisfied: anyio<4,>=3.5.0 in /Users/user/miniconda3/lib/python3.10/site-packages (from openai) (3.6.2)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/user/miniconda3/lib/python3.10/site-packages (from openai) (1.8.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/user/miniconda3/lib/python3.10/site-packages (from openai) (0.23.3)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/user/miniconda3/lib/python3.10/site-packages (from openai) (1.10.12)\n",
      "Requirement already satisfied: tqdm>4 in /Users/user/miniconda3/lib/python3.10/site-packages (from openai) (4.64.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.5 in /Users/user/miniconda3/lib/python3.10/site-packages (from openai) (4.7.1)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/user/miniconda3/lib/python3.10/site-packages (from anyio<4,>=3.5.0->openai) (2.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/user/miniconda3/lib/python3.10/site-packages (from anyio<4,>=3.5.0->openai) (1.3.0)\n",
      "Requirement already satisfied: certifi in /Users/user/miniconda3/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2022.12.7)\n",
      "Requirement already satisfied: httpcore<0.17.0,>=0.15.0 in /Users/user/miniconda3/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (0.16.3)\n",
      "Requirement already satisfied: rfc3986[idna2008]<2,>=1.3 in /Users/user/miniconda3/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.5.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/user/miniconda3/lib/python3.10/site-packages (from httpcore<0.17.0,>=0.15.0->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658406d0-c833-4776-a9f1-79bb623de8bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d6481e5-10bb-4e07-9ba2-8ec59df6bd7e",
   "metadata": {},
   "source": [
    "## ChatCompletion API\n",
    "openai 라이브러리를 통해서 openai가 제공하는 다양한 API들을 사용할 수 있습니다. 그 중에서 우리가 앞으로 가장 많이 쓰게 될 API는 ChatCompletion입니다. 이는 마치 채팅을 나누는 것 처럼, 이전 대화 텍스트를 전달하면 이어지는 대화를 생성해주는 API입니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0ccb39-f977-44e6-b727-1835c8a648eb",
   "metadata": {},
   "source": [
    "### 기본 사용법\n",
    "ChatCompletion API는 model과 messages 두 파라미터를 전달해서 사용할 수 있습니다. 응답은 json 형태로 리턴되며, 이를 잘 파싱해서 생성된 텍스트를 읽어올 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a52b12-c1e1-40cf-baa2-1a7a8f3bcef5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c69788e-ecc5-4e17-b84e-ac0054d28bc5",
   "metadata": {},
   "source": [
    "### 텍스트 생성 결과 파싱\n",
    "\n",
    "텍스트 생성 결과는 JSON 형태로 리턴됩니다. 다른 정보들도 같이 잔뜩 리턴되었는데, 그 중에서 텍스트만 읽어오겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddea1eea-2104-4345-9a65-610f895a67df",
   "metadata": {},
   "source": [
    "## model 파라미터 지정\n",
    "model은 대화 생성에 어떤 모델을 사용할 지 결정하는 파라미터입니다. 대표적으로 \"gpt-3.5-turbo\"와 \"gpt-4-1106-preview\"를 지정할 수 있습니다.\n",
    "\n",
    "gpt-3.5-turbo는 성능이 준수하고 가격이 저렴합니다. 때문에 앞으로 우리는 대부분 이 모델을 이용할 예정입니다. 다만, 복잡한 테스크의 경우에는 성능이 떨어집니다. 반면에 gpt-4-1106-preview는 기가막힌 텍스트를 생성하는 대신, 10배 정도 더 비쌉니다.\n",
    "\n",
    "한번 삼행시를 지어달라는 복잡한 테스크로 두 모델의 성능을 비교해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd8f6ab-0ad5-489f-a38b-a1a2546503de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "15e51a7e-c0d8-4826-a5f1-d1b2539facd9",
   "metadata": {},
   "source": [
    "### gpt-3.5-turbo로 복잡한 테스크 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d209fc39-7918-43f0-93d8-c97d0b2f04c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e0e2c50b-d1e5-46d3-bb00-9416b486265b",
   "metadata": {},
   "source": [
    "### gpt-4로 복잡한 테스크 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1bca3b-1a68-4195-9a07-fc91496e20b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "64a2410d-c415-4fb2-8f34-b53b877cade9",
   "metadata": {},
   "source": [
    "힘의 차이가 느껴지시나요? 이처럼 텍스트 생성 자체는 gpt-4가 압도적입니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48db129f-9cf0-4340-82da-fcdbc930fac1",
   "metadata": {},
   "source": [
    "### 어떤 모델을 선택하는 것이 좋을까?\n",
    "\n",
    "gpt-3.5-turbo는 어지간한 테스크에 대해서 준수한 성능을 보여줍니다. 때문에 gpt-3.5-turbo 만으로도 내가 원하는 수준의 텍스트가 생성되는지 먼저 확인해보는 것이 좋습니다. 만약 결과가 불만족스럽고, 비용을 지불해서라도 퀄리티를 높여야한다면 gpt-4-1106-preview를 선택하면 됩니다. (참고로 펭추리는 3.5와 4를 적절히 섞어서 사용합니다 ㅎㅎ)\n",
    "\n",
    "이 외에도 모델이 학습된 시점이나 입력으로 받을 수 있는 최대 토큰 수에 따라서 다양한 종류의 모델들이 있습니다. 궁금하신 분들은 아래 링크로 이동해서 모델마다 어떤 차이가 있는지 살펴보세요.\n",
    "\n",
    "https://platform.openai.com/docs/models/gpt-4\n",
    "https://platform.openai.com/docs/models/gpt-3-5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afad0526-1ed7-45e9-a402-3e718d5cf804",
   "metadata": {},
   "source": [
    "## role 파라미터\n",
    "그 다음 messages 파라미터를 지정해주어야 합니다. 여기에는 유저와 AI가 나눈 대화를 리스트 형태로 전달해주어야 합니다. 이 때, 대화의 화자와 내용을 딕셔너리 형태로 전달해주어야 합니다. \n",
    "\n",
    "```python\n",
    "{\"role\": \"화자\", \"content\": \"대화내용\"}\n",
    "```\n",
    "\n",
    "role에는 user, assistant, system이 있습니다. user는 유저, assistant는 chatGPT를 가리킵니다. system은 AI에게 역할을 부여할 때 사용하는데, 잠시 뒤에 알아보겠습니다. 이제 messages 파라미터를 전달할 때, 유저가 입력한 텍스트와 AI가 생성한 텍스트를 구분지어서 전달할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d380de-fa88-46c9-ad38-0f74fdfb830a",
   "metadata": {},
   "source": [
    "### AI와 대화나누기\n",
    "한번 user와 assistant가 이전에 나눈 대화를 파라미터로 전달하고, 대화를 이어서 생성해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ce81d3-489b-46b1-81b9-927621c32340",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b368988-b792-44c0-816d-6bde5c41e2a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a5a9c49-aebd-4a87-b724-dec3a937da53",
   "metadata": {
    "tags": []
   },
   "source": [
    "### AI와 대화하기 함수화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983616ce-dcd4-45fa-919b-5d52daa4fcdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "49389f09-849b-4b5b-bd2c-288701c7bc8a",
   "metadata": {},
   "source": [
    "### AI에게 역할 부여하기\n",
    "\n",
    "대화를 시작할 때, role을 system으로 지정한 다음, AI에게 역할과 성격을 부여할 수 있습니다. 만약 이런 system 메세지를 설정하지 않는다면 chatGPT는 기본적으로 \"You are an helpful assistant.\"라는 역할이 부여되게 됩니다.\n",
    "\n",
    "```python\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"당신은 주식 분석 전문가입니다.\"},\n",
    "    ...\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96df9640-5729-4028-b5d0-a7c82a46c69d",
   "metadata": {},
   "source": [
    "한번 내일 점심 메뉴를 물어보는 대화에 system message를 추가해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91de1b0-6d17-45ab-81f8-d49cdc2b18ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "15fe7f18-c779-4d40-8353-8888c5b9fcf3",
   "metadata": {},
   "source": [
    "## Streaming\n",
    "\n",
    "지금까지는 모든 텍스트가 생성되면 리턴 받는 식으로 요청을 보냈습니다. 그런데 우리가 chatGPT를 써보면, 곧바로 답변을 타닥타닥 생성합니다. \n",
    "\n",
    "API로도 이 기능을 사용할 수 있습니다. 먼저 요청을 보낼 때 stream 옵션을 True로 설정해줍니다. 그 다음, for문을 이용해서 응답으로부터 생성된 텍스트를 쭉쭉 읽어오는 겁니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd21f3f-0ca8-4b5c-af1f-a5b0d7b2efa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0ba026df-42a2-4fae-9b5c-53d0e6334960",
   "metadata": {},
   "source": [
    "유저가 질문하자마자 답변이 생성되는 걸 보여줄 수 있어서, 훨씬 유저 경험이 좋습니다. 뒤에 이어지는 서비스 개발 예시들에서도 유용하게 사용되니 잘 기억해주세요.|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05afbc8e-c56f-4f6c-8226-1fc608a888a6",
   "metadata": {},
   "source": [
    "## 마치며\n",
    "\n",
    "지금까지 chatGPT API의 거의 모든 사용법을 알아봤습니다. 생각보다 되게 쉽죠? 이 정도만 빠삭하게 알고 있어도 정말 다양한 LLM을 이용한 서비스들을 만들 수 있습니다. 다음 강의부터 본격적으로 재밌는 프로젝트들을 직접 만들어 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c113fa-40be-4c37-94d7-7d99983a64fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
