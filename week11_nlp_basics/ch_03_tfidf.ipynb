{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff748c1c-d988-4cb4-a193-30f6ea9b39fe",
   "metadata": {},
   "source": [
    "# ch 3. tf-idf\n",
    "\n",
    "이번 챕터에서는 대표적인 빈도 수 기반의 NLP 기법 중 하나인 tf-idf에 대해서 배워보겠습니다. tf-idf란 term-frequency & inverse document frequency의 약자로, 특정 문서를 벡터화 할 때 사용되는 단순하면서도 효과적인 기법입니다. tf-idf를 이용하면 문서 내에 등장하는 단어들에 중요도를 매길 수 있습니다. 이를 통해 유사한 문서 찾기, 문서 내 중요한 단어 파악하기 등의 기능을 구현할 수 있습니다. 중요도를 매긴 다는 것이 어떤 의미인지 예시를 통해서 알아보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ef58f6c-e1db-4553-9bf3-f547562e5ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = [\n",
    "    \"롯데 자이언츠의 거인 이대호(40)의 꿈이 무너져가고 있다. 이대호가 새해 40세 불혹(不惑)의 나이가 됐다. 불혹은 주위에서 어떤 일이 벌어져도 중심을 잃지 않고 자신만의 원칙을 지켜 나갈 수 있는 경지에 오르는 시기다. 이번 스토브리그에 롯데 구단에 걱정스러운 일이 벌어지고 있다. 그런데 이대호는 어떤 대외 활동도 하지 않고 침묵하며 조용히 개인 훈련에 집중하는 모습이다. 불혹이 돼서인가? 지난 2017년 1월24일이다. 벌써 5년의 시간이 흘렀다. 롯데의 프랜차이즈 스타 이대호가 일본프로야구 미국 메이저리그를 거쳐 고향팀 롯데로 돌아왔다. 그는 ‘조선의 4번타자’답게 단숨에 최고가 됐다. 삼성에서 FA가 된 최형우가 고향팀 KIA 타이거즈와 4년 계약을 하면서 기록한 총액 100억 원을 훨씬 넘어 150억 원에 롯데와 계약했다. 당시 인터뷰에서 이대호는 ‘메이저리그에서 열심히 노력해 꿈을 이루었다. 남은 것은 롯데로 돌아와 함께 우승을 하는 것이다. 마지막 소원이 롯데의 우승’이라고 밝혔다. 2001년 롯데에 2차 1순위로 입단해 2011시즌까지 11시즌 동안 이대호는 무려 225개의 홈런을 쏘아 올렸다. 그리고 2008~2011 시즌까지 4년 연속 롯데를 포스트시즌으로 이끌었으나 한국시리즈 우승을 못하고 일본 프로야구로 떠났다. 그 때도 롯데에 서운함이 있었으나 말 없이 덮었다. 4년의 계약 기간이 지나갔다. 여전히 롯데는 한국시리즈 근처에 가지 못했다. 이대호는 올해 1월29일 롯데와 2년 총액 26억 원(계약금 8억 원 연봉 8억 원)에 특별한 옵션을 걸었다. 남은 2억 원에 다른 인센티브 조건이 아니라 한국시리즈 우승 의지를 담았다. 그리고 ‘우승하면 받는 1억 원의 옵션을 불우이웃을 돕는데 모두 기부하겠다’고 약속했다. 이대호는 그 때 계약이 늦어져 팬들에게 죄송하다고 말했다. 롯데 팬들이 걱정한 것도 사실이다. 전격 은퇴를 선언할 가능성도 분명히 있었다. 같은 시기 FA 4년 계약을 했던 KIA 최형우는 이미 12월에 3년 총액 47억원(게약금 13억원, 연봉 9억원, 옵션 7억원)에 계약을 맺었다.  차이가 분명히 있다. 최형우와 나이는 1살차였지만 이대호는 4년 계약 기간 중 파워나 기여도에서 그에 뒤지지 않았다. 그런데 단 하나 최형우는 계약 첫 해인 2017시즌 김기태 감독을 도와 팀을 한국시리즈 우승으로 이끌었다. 2022시즌 이대호는 롯데와 17년을 동행하게 된다. 부산에서 태어나고 자란 이대호가 무려 17년이나 한국시리즈 우승을 못하고 유니폼을 벗게 되면 평생 자신은 물론 롯데 팬들의 마음 한켠에 빈 곳이 남아 있게 될 것이다. 그는 2년 재계약을 하면서 은퇴 배수진을 치고 ‘우승을 위해 할 수 있는 모든 것을 다하겠다. 후배들에게 내가 가진 모든 것을 전수해주겠다’고 밝혔다. 그런데 프랜차이즈 스타 손아섭이 NC 다이노스로 떠나고 강민호 재영입도 실패하면서 롯데의 한국시리즈 우승은 점점 멀어져 가고 있다. 이대호의 꿈이 무너져 간다. 이제는 그의 침묵이 어색하다.\",\n",
    "    \"지난 시즌을 끝으로 현역 생활을 마무리한 이대호(41)가 친정팀 소프트뱅크 호크스의 홈 경기장을 방문했다. 소프트뱅크는 27일 일본 후쿠오카의 페이페이돔에서 2023 일본프로야구(NPB) 지바 롯데 마린스와 홈 경기에 이대호를 초청했다. 이대호는 이날 가족, 지인들과 함께 관중석에서 경기를 관람했다.  2001년 신인 드래프트 2차 1라운드 4순위로 롯데에 입단한 이대호는 2011년 시즌을 마치고 일본 무대로 향했다. 2012~2013년 오릭스 버펄로스에서 활약한 뒤 2014년부터 2년간 소프트뱅크에 몸담았다.  이대호는 소프트뱅크에서 첫 시즌 타율 3할, 19홈런, 68타점으로 활약했다. 다음 시즌에는 타율 2할8푼2리, 31홈런, 98타점으로 불을 뿜었다.  2014~2015년 2년 연속 통합 우승에 기여했고, 2015년에는 한국인 최초로 일본시리즈 MVP(최우수 선수)에 선정됐다.  이 같은 활약으로 이대호는 2016년 메이저리그(MLB) 무대에 진출했다. 시애틀 매리너스에 입단해 한 시즌 활약한 뒤 2017년 고향팀인 롯데로 돌아온 그는 지난해 현역 은퇴를 선언한 뒤 방송인으로 활동 중이다.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d9d6c27-21a3-459e-b771-0c8f3cc668c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Komoran \n",
    "\n",
    "komoran = Komoran(userdic=\"./data/user.dic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb8ab2e4-2623-4418-b8c8-cd080a5f1e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_nouns(tokens):\n",
    "    return [text for text, tag in tokens if tag in (\"NNP\", \"NNG\")]\n",
    "\n",
    "tokens_list = [komoran.pos(sentence) for sentence in sentence]\n",
    "nouns_list = [extract_nouns(tokens) for tokens in tokens_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0a546eb-0cf0-4226-b3aa-726db5fa5968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['롯데', '자이언츠', '거인', '이대호', '꿈', '이대호', '새해', '불혹', '나이', '불혹', '주위', '일', '중심', '자신', '원칙', '경지', '시기', '이번', '롯데', '구단', '걱정', '일', '이대호', '대외', '활동', '침묵', '개인', '훈련', '집중', '모습', '불혹', '2017년 1월', '5년', '시간', '롯데', '프랜차이즈', '스타', '이대호', '일본', '프로', '야구', '미국', '메이저', '리그', '고향', '팀', '롯데', '조선', '타자', '최고', '삼성', '최형우', '고향', '팀', 'KIA 타이거즈', '계약', '기록', '총액', '롯데', '계약', '당시', '인터뷰', '이대호', '메이저', '리그', '노력', '꿈', '남은', '롯데', '우승', '마지막', '소원', '롯데', '우승', '롯데', '순위', '입단', '시즌', '시즌', '동안', '이대호', '홈런', '시즌', '연속', '롯데', '포스트', '시즌', '한국시리즈', '우승', '일본', '프로야', '구로', '때', '롯데', '말', '4년', '계약', '기간', '롯데', '한국시리즈', '근처', '이대호', '올해', '롯데', '총액', '계약금', '연봉', '옵션', '남은', '인센티브', '조건', '한국시리즈', '우승', '의지', '우승', '옵션', '불우', '이웃', '기부', '약속', '이대호', '때', '계약', '팬', '말', '롯데', '팬', '걱정', '사실', '전격', '은퇴', '선언', '시기', '계약', 'KIA', '최형우', '12월', '총액', '게', '약', '금', '연봉', '옵션', '계약', '차이', '최형우', '이대호', '계약', '기간', '파워', '기여도', '최형우', '계약', '해인', '시즌', '김기태', '감독', '팀', '한국시리즈', '우승', '시즌', '이대호', '롯데', '동행', '부산', '자란', '이대호', '17년', '한국시리즈', '우승', '유니폼', '평생', '자신', '롯데', '팬', '마음', '곳', '재계약', '은퇴', '배수진', '우승', '후배', '전수', '프랜차이즈', '스타', '손아섭', 'NC', '다이노스', '강민호', '영입', '실패', '롯데', '한국시리즈', '우승', '이대호', '꿈', '이제', '침묵'], ['시즌', '끝', '현역', '생활', '마무리', '이대호', '친정', '팀', '소프트뱅크', '홈', '경기장', '방문', '소프트뱅크', '일본', '후쿠오카', '페이', '페이', '돔', '일본', '프로', '야구', '지바 롯데 마린스', '홈', '경기', '이대호', '초청', '이대호', '이날', '가족', '지인', '관중석', '경기', '관람', '신인', '드래프트', '라운드', '순위', '롯데', '입단', '이대호', '시즌', '일본', '무대', '오릭스 버펄로스', '활약', '뒤', '2년', '소프트뱅크', '이대호', '소프트뱅크', '시즌', '타율', '홈런', '타점', '활약', '다음', '시즌', '타율', '홈런', '타점', '불', '연속', '통합', '우승', '기여', '한국인', '최초', '일본', '시리즈', '최우수 선수', '선정', '활약', '이대호', '메이저', '리그', '무대', '진출', '시애틀 매리너스', '입단', '시즌', '활약', '뒤', '고향', '팀', '롯데', '지난해', '현역', '은퇴', '선언', '뒤', '방송인', '활동']]\n"
     ]
    }
   ],
   "source": [
    "print(nouns_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b55a20-7d7d-4e0a-aea4-40a3dcaf20f6",
   "metadata": {},
   "source": [
    "### Term Frequency(TF)\n",
    "먼저 이대호 선수에 관련된 뉴스 기사 한편을 토큰화 한 뒤, 문서 내에서 토큰의 등장 빈도를 세어 보겠습니다. 문서 안에서 여러번 등장한 \"이대호\", \"롯데\"와 같은 토큰은 한번 등장한 \"손아섭\", \"NC\" 같은 토큰 보다는 더 중요한 토큰이겠죠? 이처럼 문서 내에서 자주 등장한 토큰에 가중치를 부여하기 위한 지표가 tf(term frequency)입니다. \n",
    "\n",
    "$$tf(t, d)=문서\\;내\\;특정\\;토큰\\;등장\\;빈도$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8432a0e-fe5b-4ec7-8c12-abbfbd44bf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "counters_list = [Counter(nouns) for nouns in nouns_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f05b7c9-63c3-4ca9-b99d-40dc530caa7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'롯데': 16, '이대호': 12, '우승': 9, '계약': 8, '시즌': 6, '한국시리즈': 6, '최형우': 4, '꿈': 3, '불혹': 3, '팀': 3, '총액': 3, '옵션': 3, '팬': 3, '일': 2, '자신': 2, '시기': 2, '걱정': 2, '침묵': 2, '프랜차이즈': 2, '스타': 2, '일본': 2, '메이저': 2, '리그': 2, '고향': 2, '남은': 2, '때': 2, '말': 2, '기간': 2, '연봉': 2, '은퇴': 2, '자이언츠': 1, '거인': 1, '새해': 1, '나이': 1, '주위': 1, '중심': 1, '원칙': 1, '경지': 1, '이번': 1, '구단': 1, '대외': 1, '활동': 1, '개인': 1, '훈련': 1, '집중': 1, '모습': 1, '2017년 1월': 1, '5년': 1, '시간': 1, '프로': 1, '야구': 1, '미국': 1, '조선': 1, '타자': 1, '최고': 1, '삼성': 1, 'KIA 타이거즈': 1, '기록': 1, '당시': 1, '인터뷰': 1, '노력': 1, '마지막': 1, '소원': 1, '순위': 1, '입단': 1, '동안': 1, '홈런': 1, '연속': 1, '포스트': 1, '프로야': 1, '구로': 1, '4년': 1, '근처': 1, '올해': 1, '계약금': 1, '인센티브': 1, '조건': 1, '의지': 1, '불우': 1, '이웃': 1, '기부': 1, '약속': 1, '사실': 1, '전격': 1, '선언': 1, 'KIA': 1, '12월': 1, '게': 1, '약': 1, '금': 1, '차이': 1, '파워': 1, '기여도': 1, '해인': 1, '김기태': 1, '감독': 1, '동행': 1, '부산': 1, '자란': 1, '17년': 1, '유니폼': 1, '평생': 1, '마음': 1, '곳': 1, '재계약': 1, '배수진': 1, '후배': 1, '전수': 1, '손아섭': 1, 'NC': 1, '다이노스': 1, '강민호': 1, '영입': 1, '실패': 1, '이제': 1})\n"
     ]
    }
   ],
   "source": [
    "print(counters_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af7673ce-0546-47ed-ac1f-8e3d8c78484b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'이대호': 6, '시즌': 5, '소프트뱅크': 4, '일본': 4, '활약': 4, '뒤': 3, '현역': 2, '팀': 2, '홈': 2, '페이': 2, '경기': 2, '롯데': 2, '입단': 2, '무대': 2, '타율': 2, '홈런': 2, '타점': 2, '끝': 1, '생활': 1, '마무리': 1, '친정': 1, '경기장': 1, '방문': 1, '후쿠오카': 1, '돔': 1, '프로': 1, '야구': 1, '지바 롯데 마린스': 1, '초청': 1, '이날': 1, '가족': 1, '지인': 1, '관중석': 1, '관람': 1, '신인': 1, '드래프트': 1, '라운드': 1, '순위': 1, '오릭스 버펄로스': 1, '2년': 1, '다음': 1, '불': 1, '연속': 1, '통합': 1, '우승': 1, '기여': 1, '한국인': 1, '최초': 1, '시리즈': 1, '최우수 선수': 1, '선정': 1, '메이저': 1, '리그': 1, '진출': 1, '시애틀 매리너스': 1, '고향': 1, '지난해': 1, '은퇴': 1, '선언': 1, '방송인': 1, '활동': 1})\n"
     ]
    }
   ],
   "source": [
    "print(counters_list[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698c7e9b-e816-4047-97f1-6f5a2c6c1739",
   "metadata": {},
   "source": [
    "$$tf(\\text{\"시즌\"}, d_{0})=6$$\n",
    "\n",
    "$$tf(\\text{\"시즌\"}, d_{1})=5$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776b1109-5ac0-4509-97af-9dba86828adf",
   "metadata": {},
   "source": [
    "이 외에도 tf를 계산하는 다양한 방식들이 있습니다. 특정 문서 내에서 등장하면 1, 등장하지 않았으면 0으로 할당하는 방법, 등장 빈도 수에 로그를 취하는 방법, 가장 많이 등장한 단어에 대한 등장 비율로 계산할 수도 있어서, 구현체에 따라 다릅니다.\n",
    "\n",
    "- boolean frequency: tf(t, d)=t가 d에 한번이라도 등장하면 1, 아니면 0\n",
    "- log scaled frequency: tf(t, d)=log(f(t, d) + 1)\n",
    "- augmented frequency: 최빈 단어를 분모로 target 단어의 TF를 나눈 값으로, 일반적으로는 문서의 길이가 상대적으로 길 경우, 단어 빈도값을 조절하기 위해 사용\n",
    "\n",
    "$$tf(t,d)=0.5+\\frac{0.5\\times f(t,d)}{max{f(w,d): w\\in d}}$$\n",
    "\n",
    "$$tf(\\text{\"시즌\"},\\;d_{1})=0.5+\\frac{0.5*5}{16}\\approx0.6562$$\n",
    "\n",
    "정리해보면 tf는 하나의 문서 내에서 특정 단어가 얼마나 자주 등장했는지를 측정하는 지표이며, 세부 구현은 여러가지가 있다 정도로 기억하고 넘어가겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0cf892-01f3-46c0-a6d6-008a8cc958ac",
   "metadata": {},
   "source": [
    "### Document Frequency(DF)\n",
    "두 기사의 TF를 보면 공통적으로 \"이대호\", \"롯데\"와 같은 토큰이 자주 등장하는 것을 알 수 있습니다. 그런데 \"꿈\", \"불혹\" 같은 토큰은 첫번째 기사에, \"소프트뱅크\" 토큰은 두번째 기사에만 등장했습니다. 이들 토큰은 비록 문서 내 등장 빈도는 적지만, 다른 문서에는 잘 등장하지 않는 문서의 특징을 잘 대변하는 토큰이라고 할 수 있습니다. \n",
    "\n",
    "특정 단어가 얼마나 전체 문서에서 흔하게 등장하는 지를 측정하는 지표가 df(document frequency)입니다. 이는 전체 문서에서 특정 단어가 등장한 문서 수를 집계한 수 입니다. 위 예시에서는 \"이대호\" 는 모든 문서에 등장하므로 df가 2, \"불혹\"이라는 단어는 1번 문서에만 등장하므로 df는 1이 됩니다.\n",
    "\n",
    "$$df(t):특정\\;토큰이\\;등장한\\;문서의\\;수$$\n",
    "\n",
    "$$df(\\text{\"시즌\"})=2$$\n",
    "\n",
    "$$df(\\text{\"불혹\"})=1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a5e05f-4ad8-44ab-96ae-4acc8aba158e",
   "metadata": {},
   "source": [
    "### Inverse Document Frequency(IDF)\n",
    "그런데 우리가 원하는 건 모든 문서에 등장하는 흔한 단어가 아니라, 특정 문서에만 등장하는 희귀한 단어입니다. df 값에 역수를 취해주면 특정 토큰이 얼마나 희귀한 단어인지를 나타내는 idf 값이 됩니다. 수식은 아래와 같습니다. \n",
    "\n",
    "$$idf(t, D)=log(\\frac{|D|+1}{df(t)+1})$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21edc13a-79e6-41d6-b493-9bdf44d62347",
   "metadata": {},
   "source": [
    "먼저 전체 문서의 집합을 D로 표기합니다. |D|는 전체 문서의 개수입니다. 분자는 특정 토큰 t를 포함한 문서 집합의 개수를 의미합니다. 즉, 전체 문서 개수를 특정 토큰을 포함한 문서 개수로 나눠준 값입니다. \n",
    "\n",
    "분모와 분자에 1씩 더해주는 것은 학습 데이터 셋에 등장한 적 없는 새로운 단어가 등장했을 때, df 값이 0이 되어 division by zero가 일어나는 현상을 방지하기 위함입니다. 이 때, 마치 모든 단어를 포함한 문서가 하나 있다고 가정하고 분모와 분자에 1씩 더해줍니다.\n",
    "\n",
    "마지막으로 로그를 씌워주겠습니다. 현재 우리가 수집한 2022년 한국 야구 뉴스 기사는 총 10만건 정도 됩니다. 만약 특정 기사에 딱 한번만 등장한 단어가 있다면 idf 값은 10만이 되버리겠죠? 이렇게 지나치게 큰 값이 나오는 상황을 방지하기 위해서 log를 한번 씌워줍니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2820750e-9634-4a98-8d73-0105c34ddb24",
   "metadata": {},
   "source": [
    "예시 데이터 셋으로 한번 계산해보겠습니다.\n",
    "\n",
    "$$idf(\\text{\"시즌\"}, D)=log(\\frac{2+1}{2+1})=0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb015792-c6b5-49d2-8e11-d7265ecb7366",
   "metadata": {
    "tags": []
   },
   "source": [
    "### TF-IDF\n",
    "tf와 idf 값을 조합하여 tf-idf 값을 계산합니다. tf-idf 값이 높다는 의미는 특정 문서 내에서 자주 등장하면서도, 다른 문서에는 잘 등장하지 않는 중요한 토큰임을 의미합니다.\n",
    "\n",
    "$$\\text{TF-IDF}(t, d, D)=tf(t,d)*idf(t,D)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c1b663-db13-4cb5-9c97-7603a95fa391",
   "metadata": {},
   "source": [
    "## TF-IDF를 이용한 문서 벡터화\n",
    "각 단어별 tf-idf 값을 계산할 수 있으면, 이제 문서를 벡터로 표현할 수 있습니다. 한번 간단한 예제를 풀어보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c8e39e-30a0-4966-8ad9-4bd27e3fc659",
   "metadata": {},
   "source": [
    "### 문서 단어 행렬(DTM)\n",
    "아래와 같이 네 개의 문서가 있습니다. 이를 토큰화 한 뒤, 행렬로 표기하면 아래와 같습니다. 표 안의 숫자가 곧 tf가 됩니다.\n",
    "\n",
    "- 문서1 : 먹고 싶은 사과\n",
    "- 문서2 : 먹고 싶은 바나나\n",
    "- 문서3 : 길고 노란 바나나 바나나\n",
    "- 문서4 : 저는 과일이 좋아요\n",
    "\n",
    "||과일이|길고|노란|먹고|바나나|사과|싶은|저는|좋아요|\n",
    "|-|-|-|-|-|-|-|-|-|-|\n",
    "|문서1|0|0|0|1|0|1|1|0|0|\n",
    "|문서2|0|0|0|1|1|0|1|0|0|\n",
    "|문서3|0|1|1|0|2|0|0|0|0|\n",
    "|문서4|1|0|0|0|0|0|0|1|1|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be16c4e-b49f-4fab-a43a-d23690f4d71d",
   "metadata": {},
   "source": [
    "### tf-idf 계산\n",
    "\n",
    "각 단어별 idf를 계산하면 아래와 같습니다.\n",
    "\n",
    "|단어|IDF(역 문서 빈도)|\n",
    "|-|-|\n",
    "|과일이|ln(4+1/(1+1)) = 0.9162|\n",
    "|길고|ln(4+1/(1+1)) = 0.9162|\n",
    "|노란|ln(4+1/(1+1)) = 0.9162|\n",
    "|먹고|ln(4+1/(2+1)) = 0.5108|\n",
    "|바나나|ln(4+1/(2+1)) = 0.5108|\n",
    "|사과|ln(4+1/(1+1)) = 0.9162|\n",
    "|싶은|ln(4+1/(2+1)) = 0.5108|\n",
    "|저는|ln(4+1/(1+1)) = 0.9162|\n",
    "|좋아요|ln(4+1/(1+1)) = 0.9162|\n",
    "\n",
    "tf-idf를 이용하여 각 문서를 벡터로 나타내면 아래와 같습니다.\n",
    "\n",
    "||과일이|길고|노란|먹고|바나나|사과|싶은|저는|좋아요|\n",
    "|-|-|-|-|-|-|-|-|-|-|\n",
    "|문서1|0|0|0|0.5108|0|0.9162|0.5108|0|0|\n",
    "|문서2|0|0|0|0.5108|0.5108|0|0.5108|0|0|\n",
    "|문서3|0|0.9162|0.9162|0|1.8324|0|0|0|0|\n",
    "|문서4|0.9162|0|0|0|0|0|0|0.9162|0.9162|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8238ed0-0c35-4852-b6dd-97c21eee18cb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 정리 \n",
    "이번 챕터에서는 기본적인 NLP 알고리즘 중 하나인 tf-idf 개념에 대해서 학습해보았습니다. 그리고 tf-idf를 이용해서 문서를 벡터로 나타낼 수 있었습니다. \n",
    "\n",
    "tf-idf로 벡터화 시킨 문서는 유사도를 측정하여 유사한 문장을 찾는다던가, 분류 모델을 학습시켜서 문서의 종류를 분류하는데 사용됩니다. 최근에는 딥러닝을 이용하여 문서를 벡터화 시키는 것이 대세지만, tf-idf는 충분히 그 간결함으로 많이 사용되는 기본 NLP 알고리즘입니다.\n",
    "\n",
    "이어지는 챕터에서는 scikit-learn의 Tfidf 구현체를 이용하여 실제 2022년 야구 뉴스 데이터 셋을 벡터로 표현하고, tf-idf를 활용한 문서 검색을 구현해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e300f14-997e-4027-86b1-82bf554561a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
