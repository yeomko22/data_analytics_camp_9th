{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00c37c47-bf21-4261-a826-10d52aad36db",
   "metadata": {},
   "source": [
    "# ch 5. Naive Bayes Classifier\n",
    "\n",
    "naive bayes classifier는 베이즈 정리를 사용한 가장 기본적인 텍스트 분류 기법입니다. 이번 챕터에서는 naive bayes의 기본 동작 원리를 살펴보고, 네이버 영화 리뷰 데이터 셋을 이용하여 직접 텍스트 분류 모델을 학습시켜 보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa0f3c6-4b31-447f-b6e6-71da1ea46d9a",
   "metadata": {},
   "source": [
    "## 베이즈 정리 복습\n",
    "\n",
    "베이즈 정리는 사전 확률과 사후 확률의 관계에 대한 정리라고 하였습니다. 새로운 증거를 확보하여 사전 확률을 더 신뢰도있게 갱신시키는 것이 베이즈 정리의 핵심이었습니다.\n",
    "\n",
    "$$P(H|E)=\\frac{P(E|H)P(H)}{P(E)}$$\n",
    "\n",
    "$$\\text{H: Hypothesis, 어떤 사건이 발생했다는 주장}$$\n",
    "\n",
    "$$\\text{E: Evidence, 새로운 정보}$$\n",
    "\n",
    "$$P(H):\\text{어떤 사건이 발생했다는 주장에 대한 신뢰도, 사전 확률}$$\n",
    "\n",
    "$$P(H|E):\\text{새로운 정보를 받은 후 갱신된 신뢰도, 사후 확률}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd179a8-d367-4b6a-a2ae-996a9ed37d45",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier\n",
    "\n",
    "Naive Bayes는 베이즈 정리를 이용해서 데이터를 분류하는 모델입니다. 여기서는 텍스트의 종류를 분류하는데 적용해보겠습니다.\n",
    "\n",
    "먼저 영화 리뷰 텍스트를 보고, 긍정적인 리뷰인지, 부정적인 리뷰인지 분류하고 싶다고 가정하겠습니다. 즉, 영화 리뷰가 주어졌을 때, 이 리뷰가 긍정적인 리뷰일 확률이 궁금합니다. 먼저 하나의 리뷰는 document, 하나의 document는 토큰들의 시퀀스로 표현하겠습니다. \n",
    "\n",
    "$$d=(x_{1}, x_{2}, ..., x_{n})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e287a926-2413-4810-be23-67f4f2deb50c",
   "metadata": {},
   "source": [
    "우리가 구하고 싶은 건 리뷰 텍스트가 주어졌을 때, 이 리뷰가 긍정적인 리뷰일 확률입니다. 베이즈 정리를 이용해서 표현하면 아래와 같습니다.\n",
    "\n",
    "\n",
    "$$P(pos|d)=\\frac{P(d|pos)P(pos)}{P(d)}=\\frac{P(d|pos)P(pos)}{P(d|pos)P(pos)+P(d|neg)P(neg)}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cc4a94-f5a2-4076-9954-b4ec119af4bf",
   "metadata": {},
   "source": [
    "여기서 P(pos)와 P(neg)는 사전 확률로 이미 우리가 알고 있다고 가정하겠습니다. 문서가 주어졌을 때, 이 문서가 긍정일 확률은 사후 확률에 해당합니다. 이를 알기 위해서는 P(d|pos)와 P(d|neg)를 계산해야합니다. 이를 몇가지 가정을 통해 계산하는 모델이 Naive Bayes 입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c16b5e0-07fb-41a8-9b16-b613276e47b1",
   "metadata": {},
   "source": [
    "### Naive Bays 가정\n",
    "naive bayes 몇 가지 가정을 통해 아주 간단하게 조건부 확률을 계산합니다.  \n",
    "\n",
    "1. 문서 내에서 특정 토큰이 등장하는 위치는 신경쓰지 않는다. 오로지 등장 여부만 신경쓴다.(Bag of Words assumption)\n",
    "2. 문서 내에 특정 토큰이 등장하는 사건은 서로 독립이다.(Conditional Independence)  \n",
    "\n",
    "이 가정을 적용하면 아래와 같은 수식을 작성할 수 있습니다.  \n",
    "\n",
    "$$P(d|pos)$$\n",
    "\n",
    "$$=P(x_{1},x_{2},...,x_{n}|pos)$$\n",
    "\n",
    "$$=P(x_{1} \\cap x_{2} \\cap ... \\cap x_{n}|pos)$$\n",
    "\n",
    "$$=P(x_{1}|pos)*P(x_{2}|pos)*...*P(x_{n}|pos)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee711cc-6814-45b6-80e4-afe885b97e50",
   "metadata": {},
   "source": [
    "모든 사건들이 독립이라는 것을 가정하기 때문에 이름에 Naive(순진한)이 붙은 겁니다. 이를 이용하여 사후 확률 값을 계산하고, 사후 확률이 가장 높은 클래스를 선택하는 것이 naive bayes classifier입니다. 이를 수식으로 나타내면 아래와 같습니다.\n",
    "\n",
    "$$\\hat{y}=\\underset{y}{argmax}P(y)\\prod_{i=1}^{n}P(x_{i}|y)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44cee469-ee92-42e1-83b3-fcf0813799fa",
   "metadata": {},
   "source": [
    "## 예제\n",
    "\n",
    "### 데이터 셋 준비\n",
    "실제 데이터를 살펴보면서 naive bayes 알고리즘을 이해해보겠습니다. 아래와 같이 데이터 셋이 주어졌다고 해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20796fb3-bdec-41d3-a1a0-6e4bcbd484e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    (\"This movie was awesome! I really enjoyed it.\", 0),\n",
    "    (\"This movie is just a masterpiece.\", 0),\n",
    "    (\"This movie was boring and waste of time.\", 1),\n",
    "    (\"shit, it sucks. I was almost sleeping\", 1),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc7c5e3-0cb1-40a0-8c90-17bac4b4b819",
   "metadata": {},
   "source": [
    "각 문장을 토큰화 하고, 각 단어별로 긍정일 때 등장할 조건부 확률, 부정일 때 등장할 조건부 확률을 집계해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89e21dbe-4d21-4266-b72d-d7580eb9d8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from collections import Counter\n",
    "\n",
    "tokenizer = WordPunctTokenizer()\n",
    "pos_counter = Counter()\n",
    "neg_counter = Counter()\n",
    "for review, label in data:\n",
    "    tokens = tokenizer.tokenize(review.lower())\n",
    "    if label == 0:\n",
    "        pos_counter += Counter(tokens)\n",
    "    else:\n",
    "        neg_counter += Counter(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1d141b0-18d9-4c98-bf5e-d2cb64b137ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos counter Counter({'this': 2, 'movie': 2, '.': 2, 'was': 1, 'awesome': 1, '!': 1, 'i': 1, 'really': 1, 'enjoyed': 1, 'it': 1, 'is': 1, 'just': 1, 'a': 1, 'masterpiece': 1})\n",
      "neg counter Counter({'was': 2, '.': 2, 'this': 1, 'movie': 1, 'boring': 1, 'and': 1, 'waste': 1, 'of': 1, 'time': 1, 'shit': 1, ',': 1, 'it': 1, 'sucks': 1, 'i': 1, 'almost': 1, 'sleeping': 1})\n"
     ]
    }
   ],
   "source": [
    "print(\"pos counter\", pos_counter)\n",
    "print(\"neg counter\", neg_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d502380-e870-4a15-a0d3-3880d006408b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_total_cnt = sum(pos_counter.values())\n",
    "pos_vocabs = len(pos_counter.keys())\n",
    "neg_total_cnt = sum(neg_counter.values())\n",
    "neg_vocabs = len(neg_counter.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e30ea0-b3eb-4ffa-bb6a-b911162e96a7",
   "metadata": {},
   "source": [
    "### 사전 확률\n",
    "리뷰가 긍정일 사전확률과 부정일 사전 확률은 아래와 같습니다.\n",
    "\n",
    "$$P(pos)=0.5$$\n",
    "\n",
    "$$P(neg)=0.5$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d08cc4a-54ba-417f-a1ce-8208048a5464",
   "metadata": {},
   "source": [
    "### 조건부 확률 계산\n",
    "긍정일 때 특정 단어가 등장할 확률은 아래와 같습니다. 부정일 때는 positive를 negative로만 바꿔주면 됩니다. \n",
    "\n",
    "한번도 등장하지 않은 단어가 주어졌을 때, 확률값이 0이 되어 전체 확률을 0으로 만들어버리는 현상을 방지하기 위해 분자에 1을 더해주고, 분모에는 전체 어휘의 수를 더해줍니다. 마치 모든 단어를 포함하는 문서가 하나 추가되었다고 생각하면 됩니다. 이러한 기법을 additive smoothing 혹은 laplace smoothing이라고 부릅니다.\n",
    "\n",
    "additive smoothing: https://en.wikipedia.org/wiki/Additive_smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83124d5a-f2a9-4854-9589-b5abb6df729b",
   "metadata": {},
   "source": [
    "$$P(w|pos)=\\frac{count(w, pos)+1}{\\sum_{w \\in V}count(w, pos)+V}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a4c2eb-9072-4d61-9872-e8e10f1b74b6",
   "metadata": {},
   "source": [
    "예를들어 긍정일 때, this라는 단어가 등장할 확률을 계산해보겠습니다.\n",
    "\n",
    "$$P(\\text{\"this\"}|pos)=\\frac{2+1}{17+14}=0.0967$$\n",
    "\n",
    "부정일 때, this라는 단어가 등장할 확률은 아래와 같습니다.\n",
    "\n",
    "$$P(\\text{\"this\"}|neg)=\\frac{1+1}{18+16}=0.08$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d84e634-ea06-4330-81fd-3eecde2b1d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(\"this\"|pos): 0.0967741935483871\n",
      "P(\"this\"|neg): 0.058823529411764705\n"
     ]
    }
   ],
   "source": [
    "pos_total_cnt = sum(pos_counter.values())\n",
    "neg_total_cnt = sum(neg_counter.values())\n",
    "pos_prob = (pos_counter[\"this\"] + 1) / (pos_total_cnt + pos_vocabs)\n",
    "neg_prob = (neg_counter[\"this\"] + 1) / (neg_total_cnt + neg_vocabs)\n",
    "print(f'P(\"this\"|pos): {pos_prob}')\n",
    "print(f'P(\"this\"|neg): {neg_prob}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0128e558-81ff-4944-8cb9-7d8a676ee715",
   "metadata": {},
   "source": [
    "리뷰에 단어들이 등장하는 사건을 모두 독립이라고 가정하면, 긍정일 때 특정 리뷰가 등장할 확률과 부정일 때, 특정 리뷰가 등장할 확률을 계산할 수 있습니다.\n",
    "\n",
    "$$P(d|pos)=P(\\text{\"this\"}|pos)*P(\\text{\"is\"}|pos)*...=7.69*10^{-9}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9442e99c-b71c-42e6-bdae-163485e84de1",
   "metadata": {},
   "source": [
    "부정일 때도 마찬가지로 확률을 계산해주면 됩니다.\n",
    "\n",
    "$$P(d|neg)=P(\\text{\"this\"}|neg)*P(\\text{\"is\"}|neg)*...=1.43*10^{-10}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b64ffb61-df02-4959-a0fb-0b7c44fd7ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(review|pos): 4.502333629300961e-10\n",
      "P(review|neg): 2.2399001301513285e-12\n"
     ]
    }
   ],
   "source": [
    "review_tokens = ['this', 'is', 'a', 'masterpiece', '!', 'i', 'really', 'enjoyed']\n",
    "pos_total_prob = 1\n",
    "neg_total_prob = 1\n",
    "for token in review_tokens:\n",
    "    pos_prob = (pos_counter[token] + 1) / (pos_total_cnt + pos_vocabs)\n",
    "    neg_prob = (neg_counter[token] + 1) / (neg_total_cnt + neg_vocabs)\n",
    "    pos_total_prob *= pos_prob\n",
    "    neg_total_prob *= neg_prob\n",
    "print(f\"P(review|pos): {pos_total_prob}\")\n",
    "print(f\"P(review|neg): {neg_total_prob}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166b351c-30af-4162-997b-ad591ee964bc",
   "metadata": {},
   "source": [
    "### 사후 확률 계산\n",
    "\n",
    "이제 각 조건부 확률을 계산할 수 있으니, 사후 확률을 계산해보겠습니다. 리뷰가 주어졌을 때, 긍정일 확률을 베이즈 정리를 이용하여 표현하면 아래와 같습니다.\n",
    "\n",
    "\n",
    "$$P(pos|d)=\\frac{P(d|pos)P(pos)}{P(d)}=\\frac{P(d|pos)P(pos)}{P(d|pos)P(pos)+P(d|neg)P(neg)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1105c252-2f24-4192-aab7-9f2abb884ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_prior = 0.5\n",
    "neg_prior = 0.5\n",
    "pos_posterior = (pos_total_prob * pos_prior) / ((pos_total_prob * pos_prior) + (neg_total_prob * neg_prior))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f679324-6571-4f1a-acd8-4ef31007cd17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.995049651961749"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_posterior"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b5a050-9496-4453-b63d-c2a97e60de4c",
   "metadata": {},
   "source": [
    "베이즈 정리를 이용해서 계산해보면 \"this is a materpiece! i really enjoyed\"라는 리뷰가 긍정일 확률은 98%였습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc5beb8-6ad7-40e1-af97-e54d1055d7a6",
   "metadata": {},
   "source": [
    "## Naive Bayes 한계\n",
    "\n",
    "Naive Bayes의 가정 때문에 문제가 한계가 있습니다. 먼저 토큰의 등장 위치는 중요합니다. 동일한 토큰일 지라도 앞 뒤에 어느 토큰이 오느냐에 따라서 의미가 달라질 수 있습니다. \n",
    "\n",
    "또한 각 토큰이 등장하는 사건은 독립 사건이 아닙니다. 앞에 어느 토큰이 오는지에 따라서 뒤에 어떤 토큰이 올지 결정되기도 합니다. 즉, 텍스트 데이터에서 각각의 토큰은 서로 연관이 있습니다.\n",
    "\n",
    "그럼에도 불구하고 Naive Bayes는 몹시 가볍고 단순하다는 장점이 있습니다. 때문에 스팸 필터, 텍스트 분류 등의 테스크에서 활용되는 알고리즘입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f28372-87fa-4f30-ace5-33ce6c27170d",
   "metadata": {},
   "source": [
    "## 정리\n",
    "\n",
    "이번 챕터에서는 베이즈 정리를 이용하여 텍스트를 분류하는 naive bayes classifier에 대해서 알아보았습니다. naive bayes는 굉장히 가벼우면서도 상당한 성능을 보여주어 실제로 간단한 테스크들에 사용되는 기법입니다. 또한 베이즈 정리 개념을 복습하기에도 매우 좋습니다. \n",
    "\n",
    "다음 챕터에서는 실제 네이버 영화 리뷰 데이터 셋을 가지고 리뷰가 긍정인지 부정인지 분류하는 모델을 학습시켜 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da26906-3d19-42bb-ade1-f539d2fbf2e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
