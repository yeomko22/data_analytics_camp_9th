{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bf36e4d-ac8e-4c0c-849b-72348c00c26a",
   "metadata": {},
   "source": [
    "# ch 1. Tokenize\n",
    "자연어 처리에서 텍스트 데이터를 corpus(코퍼스, 말뭉치)라고 부릅니다. 크롤링 시간에 수집했던 뉴스 기사들도 코퍼스라고 부를 수 있습니다. 주어진 코퍼스(corpus)에서 토큰(token)이라 불리는 단위로 나누는 작업을 토큰화(tokenization)라고 합니다. \n",
    "\n",
    "토큰은 컴퓨터가 텍스트를 처리하는 최소 의미 단위가 됩니다. 토큰화에는 여러 기법들이 있습니다. 딥러닝 등장 이전의 NLP에서는 주로 언어학 관점에서 정의한 최소 의미 단위인 형태소를 기준으로 토큰화를 했습니다. 하지만 최근 딥러닝 모델들은 데이터로부터 자연스럽게 토크나이저를 학습하는 subword 토큰화를 사용하며, 딥러닝을 이용한 NLP 시간에 배워보겠습니다.\n",
    "\n",
    "형태소 단위로 문장을 토큰화 해주는 기술을 형태소 분석기라고 부릅니다. 형태소 분석기는 언어학적으로 해석이 가능한 장점이 있습니다만, 고유명사나 신조어 대응이 어려운 한계가 있습니다. 이번 챕터에서는 기본적인 토큰화 기법들과 형태소 분석기를 실습해보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a16dc3-6cb4-4e9e-9164-c57f1c4a018d",
   "metadata": {},
   "source": [
    "## 공백 기준의 토큰화\n",
    "먼저 생각할 수 있는 가장 단순한 토큰화 기법은 공백을 기준으로 잘라내는 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa8cd30-bdb8-4bbe-996d-394c9c0e7292",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c83b0328-292d-414b-9a9e-c383419efc5b",
   "metadata": {},
   "source": [
    "이렇게 공백을 기준으로 토큰을 만들게 되면 한국어의 특성상 조사를 떼어낼 수가 없습니다. 즉, \"이대호가\", \"이대호는\"과 같이 실제로는 비슷한 의미를 갖는 토큰을 전혀 다른 토큰으로 인식하게 됩니다. 토큰화가 제대로 이루어지지 않으면 제 아무리 고도화 된 AI 모델을 학습시킨다 하더라도 정확도를 기대할 수 없습니다.\n",
    "\n",
    "공백을 기준으로 잡는 것 외에도 온 점이나 쉼표를 기준으로 토큰화를 하는 기법들이 있지만, 마찬가지로 낮은 정확도로 인해 사용하지 않습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c1905d-c9b8-46a4-ad93-f28da0c8b410",
   "metadata": {},
   "source": [
    "## 형태소 분석기를 이용한 토큰화\n",
    "다음으로 형태소 분석기를 이용한 토큰화를 해보겠습니다. 가장 쉽게 사용할 수 있는 konlpy의 komoran을 사용하여 실습을 진행해보겠습니다. konlpy는 한국어 자연어 처리 라이브러리이고, komoran은 konlpy를 통해 이용할 수 있는 형태소 분석기 중 하나입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bd65c5-4c70-4bc5-a181-1e2b8ee7f6c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4fdf5895-f091-4152-992e-e5e1a421b510",
   "metadata": {},
   "source": [
    "형태소 분석기를 이용하면 각 토큰별로 품사와 함께 토큰화 된 텍스트를 가져올 수 있습니다. 또한 \"롯데 자이언츠\"처럼 중간에 공백이 삽입된 명사도 고유명사로 잘 구분하는 모습을 보여줍니다. \"이대호가\", \"이대호는\"과 같은 단어도 \"이대호\", \"가\", \"이대호\", \"는\"으로 분리해주어 의미 단위로 토큰을 잘 분리하는 모습을 보여줍니다.\n",
    "\n",
    "하지만 형태소 분석기는 신조어나 고유 명사에 상당히 취약한 모습을 보이기도 합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f87ffe-4eb4-400d-831b-b7dc75f6c104",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ccb5586-69a2-4d83-bb32-05460b0fdc81",
   "metadata": {},
   "source": [
    "\"SSG\", \"랜더스\", \"안우진\" 등의 고유 명사를 NNP로 잡아내지 못하는 모습을 보입니다. 이러한 형태소 분석기의 한계점은 고유 명사를 직접 지정하는 사용자 사전 기능으로 극복할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c34a475-2b40-4295-8e07-0ef7228ece56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7a349110-e507-4a92-86c0-7608ec3c6f89",
   "metadata": {},
   "source": [
    "## 전체 데이터 셋 토크나이즈\n",
    "\n",
    "웹 크롤링 시간에 정규 표현식을 이용해서 전처리 했었던 데이터 셋을 tokenize 해보겠습니다. 한번 전체 데이터 셋 중 1000개만 토큰화하여 결과를 CSV 파일에 써보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d036c3-e6a9-4bda-a158-37a88ea4a161",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9cf3cf25-631e-42b3-a97f-26546f17b10c",
   "metadata": {},
   "source": [
    "## 정리\n",
    "이번 챕터에서는 python에서 자연어를 처리하기 위한 첫 스텝인 토큰화에 대해서 알아보았습니다. 그리고 토큰화 방식 중에 하나인 형태소 기반의 토큰화를 알아보았고, konlpy Komoran을 이용해서 토큰화를 해보았습니다.\n",
    "\n",
    "한국어 형태소 분석기에는 Komoran만 있는 것은 아닙니다. 속도 측면에서는 Mecab, 정확도 측면에서는 Khaiii라는 프로젝트가 우수합니다만, 각각 설치 및 사용자 사전 등록이 까다로워서 수업 자료에 사용하지는 않았습니다. 실제 프로젝트를 진행할 때 Komoran의 성능이 아쉽다면 선택해볼만 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec3e2e7-e2ba-4403-9e70-085bb5ad26a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
